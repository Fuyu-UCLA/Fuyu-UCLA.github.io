---
layout: post
title:  "Homework 3"
categories: blog assignment
---

In this blog, I learn machine lerning with Tensorflow.
I implement a program to teach a machine learning algorithm to distinguish between pictures of dogs and pictures of cats.

<h1>§1. Load Packages and Obtain Data</h1>

First, import some livraries I use

```python
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras import utils, models, layers
```

To create a Tensorflow Dataset for training, validation, and test, run code below.
Dataset is as a pipeline to give data to machine learning model.
```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

In this case, use <b>keras.utils.image_dataset_from_directory</b> to construct a dataset.

* The most important argument is the first one, which says where the images are located. 
* The shuffle argument says that, when retrieving data from this directory, the order should be randomized. 
* The batch_size determines how many data points are gathered from the directory at once. 
<br>(ex)each time we request some data we will get 32 images from each of the data sets. 
* The image_size specifies the size of the input images, just like you’d expect.
<br><br><br>
And get names of classes
```python
names = train_dataset.class_names
```
names =   ![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic1.png){: height="30px" width="auto"}

<br><br><br>

This is technical code related to rapidly reading data (<a href="https://www.tensorflow.org/guide/data_performance">details</a>)
```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```
<br><br><br>
<h2>Working with Datasets</h2>

Here, check pictures.
In the first row, show three random pictures of cats. In the second row, show three random pictures of dogs.
```python
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))

def pic_dogs_cats(dataset):
    # to check picture in train data set with for loop
    # image: get picture data
    # animal: get number of the animal name(0: cat, 1: dog)
    for image, animal in dataset.take(1):
        # to count number of loops
        count = 0
        for i in range(len(animal)):
        # in first 3 times, skip dogs pictures(#1)
        if (count < 3):
            if (animal[i] != 0):
                continue
        # times after 3, skip cats pictures(#0)
        else:
            if (animal[i] != 1):
                continue

        ax = plt.subplot(3, 3, count + 1)
        expand_image = tf.expand_dims(image[i], 0)
        plt.imshow(expand_image[0] / 255)
        plt.title(names[animal[i]]) 
        plt.axis('off')
        
        count += 1
        # show 6 pictures, loop end
        if (count == 6):
            break
            
    plt.show()

pic_dogs_cats(train_dataset)
```
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic2.png){: height="500px" width="auto"}
<br><br><br>
<h2>Check Label Frequencies</h2>

Create an iterator called labels and make list of all animals name number.

Then compute numbers of cats(#0) and dogs(#1)
```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()

# list to record animal name(0: cats, 1: dogs)
list_animal = list(labels_iterator)

"Number of pictures of cats is: {}, pictures of dogs is: {}".format(list_animal.count(0), list_animal.count(1))
```
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic3.png){: height="50px" width="auto"}

<h1>§2. First Model</h1>

Create "tf.keras.Sequential" model. 

This model has 2 conv2D layers, 2 MaxPooling2D layers, 1 Flatten layer, 1 Dropout layer, and 2 Dense layers.
In the last Dense layer, the number of exits is set to two, the number of elements in the class.

Then, model compile in here.

```python
model1 = tf.keras.Sequential(
            [
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.MaxPooling2D((2, 2)),
                layers.Conv2D(32, (3, 3), activation='relu'),
                layers.MaxPooling2D((2, 2)),
                layers.Flatten(),
                layers.Dropout(rate=0.2),
                layers.Dense(32, activation="relu"),
                layers.Dense(2) # number of classes (cats and dogs)
            ]
)

model1.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])
```

Train model1 20 times. 
```python
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
Result of this training is below, 

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic4.png){: height="300px" width="auto"}

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic5.png){: height="300px" width="auto"}

The accuracy of my model stabilized between <strong>58% and 60%</strong> during training. Therefore, this training results are better than the baseline.

No overfitting have occurred.

<h1>§3. Model with Data Augmentation</h1>

Now add some data augmentation layers to model. 

Data augmentation refers to the practice of including flipped the same pictures upside down or rotate it 90 degrees in the training set.

Include such transformed versions of the pictures in training process in order to help model learn so-called invariant features of our input images.

```python
rand_flip = tf.keras.layers.RandomFlip("horizontal_and_vertical", seed=None)

rand_rot = tf.keras.layers.RandomRotation(
                    0.2,
                    fill_mode='reflect',
                    interpolation='bilinear',
                    seed=None,
                    fill_value=0.0
                )

model2 = tf.keras.Sequential(
            [
                rand_flip,
                rand_rot,
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.MaxPooling2D((2, 2)),
                layers.Conv2D(32, (3, 3), activation='relu'),
                layers.MaxPooling2D((2, 2)),
                layers.Flatten(),
                layers.Dropout(rate=0.2),
                layers.Dense(32, activation="relu"),
                layers.Dense(2) # number of classes (cats and dogs)
            ]
)

model2.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])
```

Train model 2 20 times.

```python
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic6.png){: height="300px" width="auto"}

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic7.png){: height="300px" width="auto"}

The accuracy of my model stabilized between <strong>65% and 66%</strong> during training. Therefore, this training results are better than the baseline.
In comparison to the accuracy obtained with model1, model 2 has better validation accuracy. 
No overfitting have occurred.

<h1>§4. Data Preprocessing</h1>

The following code will create a preprocessing layer called preprocessor which you can slot into your model pipeline.

```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])

model3 = tf.keras.Sequential(
            [
                preprocessor,
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.MaxPooling2D((2, 2)),
                layers.Conv2D(32, (3, 3), activation='relu'),
                layers.MaxPooling2D((2, 2)),
                layers.Flatten(),
                layers.Dropout(rate=0.2),
                layers.Dense(32, activation="relu"),
                layers.Dense(2) # number of classes (cats and dogs)
            ]
)
model3.compile(optimizer="adam",
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=["accuracy"])
```

Train model 3 20 times.

```python
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic8.png){: height="300px" width="auto"}

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic9.png){: height="300px" width="auto"}

The accuracy of my model stabilized between <strong>68% and 70%</strong> during training. Therefore, this training results are better than the baseline.
In comparison to the accuracy obtained with model1, model 3 has much better validation accuracy. 
No overfitting have occurred.


<h1>§5. Transfer Learning</h1>

For this task, use a pre-existing model someone have already trained a model that does a related task, and have learned some relevant patterns.

To do this, first access a pre-existing base model: MobileNetV2 here, incorporate it into a full model for our current task, and then train that model.

```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

Add "preprocessor", "rand_flip", and "rand_rot" from previouse models, and "base_model" to model 4.

Then compile it.
```python
model4 = tf.keras.Sequential(
            [
                preprocessor,
                rand_flip,
                rand_rot,
                base_model,
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.Dropout(rate=0.2), # randomly "drop" or delete 20% of connections between the previous layer and the next layer
                layers.GlobalAveragePooling2D(), # take the average
                layers.Dense(2) # number of classes (cats and dogs)
                
            ]
)

model4.compile(optimizer="adam",
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=["accuracy"])
```

Train model 4 20 times.

```python
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic10.png){: height="300px" width="auto"}

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic11.png){: height="300px" width="auto"}

The accuracy of my model stabilized between <strong>97% and 98%</strong> during training. Therefore, this training results are better than the baseline.
Model 4 has almost 100% near perfect validation accuracy. 
No overfitting have occurred.

<h1>§6. Score on Test Data</h1>

Finally, use the models I have trained so far to verify the actual percentage of correct responses.

<h2>Model 1</h2>

```python
# To count number of correct result
num_correct = 0
# To count number of all images in test_set
num_images = 0

for image, name in test_dataset:
  """
  In test_dataset, there are 6 separated datasets.
  In this loop, examine each of the six separate sets of data one at a time.
  """
  # Make prediction with trained model
  pred = model1.predict(image)
  # From prediction made above, get 
  labels_pred = pred.argmax(axis=1)

  count = 0
  for n in name:
    """
    In this loop, the model's predictions are compared with the actual responses, 
    and if they match, the number of correct answers is recorded in "num_correct"
    num_images records number of all pictures in test_dataset
    """
    num_images += 1
    if (n==labels_pred[count]):
      num_correct += 1
    count += 1

# Calculate the percentage of correct answers by dividing the number of correct answers by the number of pictures.
print("models 1 : {} % correct".format(num_correct / num_images * 100))
```

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic12.png){: height="80px" width="auto"}

<h2>Model 2</h2>

```python
num_correct = 0
num_images = 0
for image, name in test_dataset:
  pred = model2.predict(image)
  labels_pred = pred.argmax(axis=1)
  count = 0
  for n in name:
    num_images += 1
    if (n==labels_pred[count]):
      num_correct += 1
    count += 1
print("models 2 : {} % correct".format(num_correct / num_images * 100))
```
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic13.png){: height="80px" width="auto"}

<h2>Model 3</hs>

```python
num_correct = 0
num_images = 0
for image, name in test_dataset:
  pred = model3.predict(image)
  labels_pred = pred.argmax(axis=1)
  count = 0
  for n in name:
    num_images += 1
    if (n==labels_pred[count]):
      num_correct += 1
    count += 1
print("models 3 : {} % correct".format(num_correct / num_images * 100))
```

![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic14.png){: height="80px" width="auto"}

<h2>Model 4</hs>

```python
num_correct = 0
num_images = 0
for image, name in test_dataset:
  pred = model4.predict(image)
  labels_pred = pred.argmax(axis=1)
  count = 0
  for n in name:
    num_images += 1
    if (n==labels_pred[count]):
      num_correct += 1
    count += 1
print("models 1 : {} % correct".format(num_correct / num_images * 100))
```
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic15.png){: height="80px" width="auto"}