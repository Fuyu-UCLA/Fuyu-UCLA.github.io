---
layout: post
title:  "Homework 3"
categories: blog assignment
---

```python
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras import utils, models, layers
```

```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)

names = train_dataset.class_names
```

```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```


```python
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))

for image, animal in train_dataset.take(1):
    count = 0
    for i in range(len(animal)):
        if (count < 3):
            if (animal[i] != 0):
                continue
        else:
            if (animal[i] != 1):
                continue
                
        first_image = image[i]
        ax = plt.subplot(3, 3, count + 1)
        expand_image = tf.expand_dims(first_image, 0)
        plt.imshow(expand_image[0] / 255)
        plt.title(names[animal[i]])
        first_image = image[i] 
        plt.axis('off')
        
        count += 1
        if (count == 6):
            break
        
plt.show()
```
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic1.png) 

```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()

num_cat = 0
num_dog = 0

for i in labels_iterator:
    if (i == 0):
        num_cat += 1
    else:
        num_dog += 1

num_cat, num_dog
```
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic2.png) 
```python
model1 = tf.keras.Sequential(
            [
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Conv2D(32, (3, 3), activation='relu'),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Flatten(),
                layers.Dropout(rate=0.5),
                layers.Dense(32, activation="relu"),
                layers.Dense(32, activation="relu")
            ]
)

model1.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])
```

```python
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
the accuracy of my model stabilized <bold>between 56% and 62% </bold>during training.
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic3.png) 
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic4.png) 
```python
rand_flip = tf.keras.layers.RandomFlip("horizontal_and_vertical", seed=None)

rand_rot = tf.keras.layers.RandomRotation(
                    0.2,
                    fill_mode='reflect',
                    interpolation='bilinear',
                    seed=None,
                    fill_value=0.0
                )

model2 = tf.keras.Sequential(
            [
                rand_flip,
                rand_rot,
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Conv2D(32, (3, 3), activation='relu'),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Flatten(),
                layers.Dropout(rate=0.5),
                layers.Dense(32, activation="relu"),
                layers.Dense(32, activation="relu")
            ]
)
# model2.add(rand_flip)
# model2.add(rand_rot)

model2.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])
```

```python
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
the accuracy of my model stabilized <bold>between 52% and 63% </bold>during training.
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic5.png) 
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic6.png) 
```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])

model3 = tf.keras.Sequential(
            [
                preprocessor,
                rand_flip,
                rand_rot,
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Conv2D(64, (3, 3), activation='relu'),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Conv2D(64, (3, 3), activation='relu'),
                layers.Flatten(),
                layers.Dropout(rate=0.5),
                layers.Dense(32, activation="relu"),
                layers.Dense(64, activation="relu")
            ]
)
model3.compile(optimizer="adam",
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=["accuracy"])
```

```python
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
the accuracy of my model stabilized <bold>between 60% and 73% </bold>during training.
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic7.png) 
![image-example.png]({{ site.baseurl }}/images/pic16B-HW3-pic8.png) 
```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])


model4 = tf.keras.Sequential(
            [
                base_model_layer,
                preprocessor,
                rand_flip,
                rand_rot,
                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Conv2D(64, (3, 3), activation='relu'),
                layers.MaxPooling2D(pool_size=(2, 2)),
                layers.Flatten(),
                layers.Dropout(rate=0.5),
                layers.Dense(32, activation="relu"),
                layers.Dense(32, activation="relu")
            ]
)

model4.compile(optimizer="adam",
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=["accuracy"])
```

```python
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

```python
```